{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# model\n",
    "\n",
    "Please refer to README file for project overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"../../../DATA/behavioral_cloning_data/\"\n",
    "processed_images_dir = \"processed_images_64/\"\n",
    "image_final_width = 64\n",
    "model_name = \"model_p3_keras_tf_vgg_16_224x224x3a_\"\n",
    "nb_epoch = 1\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported rows 8037\n"
     ]
    }
   ],
   "source": [
    "import DataHelper\n",
    "#print(DataHelper.__doc__)\n",
    "from DataHelper import test_read_csv, read_csv\n",
    "#print(read_csv.__doc__)\n",
    "#test_read_csv()\n",
    "# fetch actual log of driving data\n",
    "headers, data = read_csv(data_dir + \"driving_log.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Create Labels: steering value classes\n",
    "\n",
    "- Please review notebook \"preprocessing\", section: \"Steering value distribution\".\n",
    "- Training labels have values ranging from -1 to +1.\n",
    "- When you steer with **keyboard** the STEPS are rather corse, so I think I can get away with **discrete steering angles, i.e. classes**.\n",
    "- I will start training with 21 equally spread classes, if needed I will increase to 41.\n",
    "- I want to make sure that my classes include **0.0 (zero)** as it is most common value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering_classes [-1.  -0.9 -0.8 -0.7 -0.6 -0.5 -0.4 -0.3 -0.2 -0.1  0.   0.1  0.2  0.3  0.4\n",
      "  0.5  0.6  0.7  0.8  0.9  1. ]\n",
      "Number of classes 21\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEWCAYAAACaBstRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a5f8588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "number_of_classes = 21 # desired number of classes, could be 41, too.\n",
    "steering_classes = np.linspace(-1, 1, num=number_of_classes, endpoint=True) \n",
    "steering_classes = np.sort(steering_classes)\n",
    "print(\"steering_classes\", steering_classes)\n",
    "number_of_classes = steering_classes.shape[0]\n",
    "print(\"Number of classes\", number_of_classes)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(steering_classes, 'b.')\n",
    "plt.margins(0.1)\n",
    "plt.title(\"Distribution of steering value classes.\")\n",
    "plt.xlabel(\"class number\")\n",
    "plt.ylabel('steering value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Split data into training, testing and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent_validation 0\n",
      "training (6831, 7)\n",
      "testing (1205, 7)\n",
      "validation (0, 7)\n"
     ]
    }
   ],
   "source": [
    "from DataHelper import split_random\n",
    "\n",
    "# keras actually does it's own split, so here I just reserve small validation set.\n",
    "training, testing, validation = split_random(data, percent_train=85, percent_test=15) \n",
    "\n",
    "print(\"training\",training.shape)\n",
    "print(\"testing\",testing.shape)\n",
    "print(\"validation\",validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Extract training features (images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6831,)\n",
      "IMG/center_2016_12_01_13_32_46_084.jpg\n"
     ]
    }
   ],
   "source": [
    "from DataHelper import get_image_center_values \n",
    "image_names = get_image_center_values(training)\n",
    "print(image_names.shape)\n",
    "print(image_names[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Create a list of image paths pointing to 64px version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../DATA/behavioral_cloning_data/processed_images_64/IMG/center_2016_12_01_13_32_46_084.jpg\n"
     ]
    }
   ],
   "source": [
    "image_paths = []\n",
    "for image_name in image_names:\n",
    "    image_paths.extend([data_dir + processed_images_dir + image_name])\n",
    "print(image_paths[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_images matrix shape (6831, 14, 64, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABsCAYAAAB6kUkRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADS1JREFUeJzt3VuMXXUVx/HvojOlMC3T6TW9RSQUSmOkEMIlGCIgpBIj\nPvgg+sADSV8wwcREISYmPpigD4oPxqRRFBMFI4oQQoQGEV5MS2tBC6WlVzqdttMCpZeZXqYsH86u\nGWavTfe57TPnP79PMjlzVvc5+/8/53/WnO7/zdwdERHpfhd1ugAiItIaSugiIolQQhcRSYQSuohI\nIpTQRUQSoYQuIpIIJXQRkUQooYuIJKKphG5mq81sm5ntMLOHW1UoERGpnzU6U9TMpgHbgbuAQeB1\n4D53f7t1xRMRkbJ6mnjsjcAOd98FYGZPAfcChQndzJJaZ8DMwng7llOIzqVlG6SdojZ30UX5/9RH\nsbNnzzZ1nqradj3njo7t6cmn0ChWlCvKGhkZOeLu8y90XDMJfQmwb9z9QeCmJp6vZaIXr54X9OOP\nP87FokYbvXEAY2NjpZ6zHtOnT8/FTp8+3dRzSjrKtu96EmXUvmfOnJmLXXLJJbnY0NBQLlZUxt7e\n3lws+rxEn6tmRec+c+ZMeGz0eixYsCAXmzt3bqnHFolep02bNu0t89hmEnr07uRai5mtAdY0cR4R\nESmhmYQ+CCwbd38pkPuz7O5rgbWQ3iUXEZHJpJlO0R5qnaJ3AvupdYp+093f+pTHRN/gc8dNmzYt\nfHx02SMS/Xft3Llz4bFR/WfMmJGLnTp1qtS5i1x66aW5WFSfkydPho/X9XJpl6LPW9Rm+/v7c7G+\nvr5cbPHixbnYyMhIeJ4TJ06UOja6FFJ02XF0dLTUsdGlzKJyNiM6T1E8ugz04YcfbnL3Gy50noa/\nobv7mJl9G3gRmAY8/mnJXERE2quZSy64+wvACy0qi4iINEEzRUVEEqGELiKSCCV0EZFENHUNvRET\nR7VEozfaMYGgHtGIlnomFkUjasr2nBdNvogmb0Q9+SKtUnaCXvTZ2LhxY6nHQjzSI5rAFE3YiUbi\nFJUpyjX79+8vdRzEo2yiETrR57JoslJRvFH6hi4ikggldBGRRCihi4gkQgldRCQRDU/9b+hkTa7l\nUnbpzrKxItEU4Xpep+hcF198canHqqNTPk2VSzZHnZVRJ2TUthctWpSL1dPZ+NFHH+ViR48ezcWK\nluSIPoPRlPqo83X+/HiV2jlz5uRi0fsRLR1c1PkZdaoeP348Fztw4ECpqf/6hi4ikggldBGRRCih\ni4gkQgldRCQRlXeKTlx7uZ6t4aKyRmuft6NO0ZrPAwMD4bGzZ8/OxaI11qPOk6hDBOJ10g8dOhQe\nK9IuZQccRJ+Xoo7BaD32qAMy6qyMOjoh7kB9//33c7HDhw/nYvUMoIjyT5TT5s2bFz4+ike5YvPm\nzeoUFRGZSpTQRUQSoYQuIpKIplZbNLM9wHHgHDBW5hqPiIi0R1OdollCv8Hdj5Q83id2OESdCs2K\nOhUuu+yy8NhoWdoVK1aUOq6o8yTqaNm1a1cuNjQ0lItpM2hpp2YHIZR11VVX5WJFgwiiGallP0NF\nHa3RuZYuXVrquGiwAsSzV48cyae+Y8eO5WJFm1nX8RqrU1REZCppNqE78JKZbTKzNa0okIiINKbZ\nHYtudfchM1sArDOzd9z9tfEHZIleyV5EpM2a+obu7kPZ7TDwDHBjcMxad79BHaYiIu3VcEI3sz4z\nm3X+d+BuYEurCiYiIvVpeJSLmV1B7Vs51C7d/NHdf3yBx5Q6WdHGr/39/blY1EsdTRsuGuUSjYjZ\ntm1bLlZ22jDEm0RHoinPRaN+NPpF2qVo5EsUj9phs20z+gwuWbIkF1u4cGEuVvR52bdvXy4WbQgd\nKdr8PTr/4sWLc7FoRFy07jnA8PBwLhaNpjl+/HipUS4NX0N3913AtY0+XkREWkvDFkVEEqGELiKS\nCCV0EZFEVLoeek9Pj8+aNesTsWiN42iKLsSdnVGnyMGDB3OxPXv2hM8ZrSle9jVpx2tXtJxA1IFa\nNEVZ0lXUPtqxhEak7NIB0XT+osECY2NjpZ6z7LrpEG9SHQ2giPYfKOo8Lbv/QLRpdtGgjKj80eCP\nDRs2aOq/iMhUooQuIpIIJXQRkUQooYuIJKLSTtGBgQG//fbbPxGLOiWKZmBG8Wgz2NHR0VxMMy0n\nl2g2XfS+FYk6yKIOw6gjrqoOxKms7CxTiN/L6H2LZpSeOnWqdJmi88ydOzcXi2aEQrz5e5R/du7c\nmYuNjIyUKSIQd6AeO3ZMnaIiIlOJErqISCKU0EVEEqGELiKSCCV0EZFEVDrKpbe31yf2KkfT14t6\nrqOds8uuPV40ZbnsyAhpXDQVOmp30ete9F5E71vZ0StReYp2ZZfG1DPKJVom4MyZM7lYweiP8Dmj\n9tHskh7RPg3RMiXRWu5FbXP37t252HvvvRcdqlEuIiJTiRK6iEgilNBFRBJxwYRuZo+b2bCZbRkX\nm2Nm68zs3ew2vy6liIhU6oKdomZ2G3AC+L27fy6L/RT4wN0fNbOHgQF3//4FT1Zyk2iZmuqZ2h11\nekWPj6ZcR51b9UzNltaKNmWO1kgvexyUX06gr68vFyvaZyDqqC1r4j4Q5y1btiwXi/aIePXVV1vT\nKerurwEfTAjfCzyR/f4E8LULPY+IiLRX/k9eOQvd/QCAux8wswVFB5rZGmBNg+cREZGSGk3opbn7\nWmAt6JKLiEg7NTrK5ZCZLQLIbodbVyQREWlEo9/QnwPuBx7Nbp9ttADRjLKiWZ1lZ59pvevJJerM\nWr58eS62cuXKXGzz5s3hc+7du7fh8mhz7c6I2gHEM0Wjzs6ym0nX4+TJk6WP7e3tzcWinBSVM9r3\nAWDr1q252Pbt20uXaaIywxafBP4FXG1mg2b2ALVEfpeZvQvcld0XEZEOuuA3dHe/r+Cf7mxxWURE\npAmaKSoikggldBGRRFS6fG6zwxaLOktbTRtKt1bZGX7RJrwnTpwIn/PKK6/MxaKO1vXr1+diw8Ma\nlNVu0UzNaFYmwMBAfuWQ6DM4ODiYixUNgIg6MKPnjI4rmp3cTF6IXg+oa6luLZ8rIjKVKKGLiCRC\nCV1EJBFK6CIiiVBCFxFJRNsX52qldow+qWrkzFRWdsr26OhoLlb0/kQjHqLNdbXOeWdEozeK3sv+\n/v5SsWj6fNEm0WWXd6hnOYFovf2oTtG66fVsPF/Puu8T6Ru6iEgilNBFRBKhhC4ikggldBGRRFQ9\n9f8wsBeYBxyp7MTVSK1Oqs/kl1qdVJ9in3H3/O7RE1Sa0P9/UrONZdYl6Cap1Un1mfxSq5Pq0zxd\nchERSYQSuohIIjqV0Nd26LztlFqdVJ/JL7U6qT5N6sg1dBERaT1dchERSUTlCd3MVpvZNjPbYWYP\nV33+VjCzx81s2My2jIvNMbN1ZvZudpvfhmWSMrNlZvaKmW01s7fM7KEs3pV1MrMZZrbBzN7M6vOj\nLP5ZM1uf1edPZja902Wth5lNM7PNZvZ8dr/b67PHzP5rZm+Y2cYs1pVtDsDMZpvZ02b2TvZZuqXq\n+lSa0M1sGvBL4MvASuA+M1tZZRla5HfA6gmxh4GX3X058HJ2v1uMAd9192uAm4EHs/elW+t0GrjD\n3a8FVgGrzexm4CfAz7P6fAg80MEyNuIhYOu4+91eH4Db3X3VuOF93drmAH4B/N3dVwDXUnuvqq2P\nu1f2A9wCvDju/iPAI1WWoYV1uRzYMu7+NmBR9vsiYFuny9hE3Z4F7kqhTsClwL+Bm6hN8ujJ4p9o\ni5P9B1iaJYQ7gOcB6+b6ZGXeA8ybEOvKNgdcBuwm65fsVH2qvuSyBNg37v5gFkvBQnc/AJDdLuhw\neRpiZpcD1wHr6eI6ZZcn3gCGgXXATuCou59fh7Tb2t5jwPeA87siz6W76wPgwEtmtsnM1mSxbm1z\nVwCHgd9ml8V+bWZ9VFyfqhN6tCCyhtlMEmY2E/gL8B13jxea7hLufs7dV1H7ZnsjcE10WLWlaoyZ\nfQUYdvdN48PBoV1Rn3FudffrqV2CfdDMbut0gZrQA1wP/MrdrwNO0oHLRVUn9EFg2bj7S4GhisvQ\nLofMbBFAdjvc4fLUxcx6qSXzP7j7X7NwV9cJwN2PAv+k1jcw28zO7x7QTW3vVuCrZrYHeIraZZfH\n6N76AODuQ9ntMPAMtT+83drmBoFBd1+f3X+aWoKvtD5VJ/TXgeVZ7/x04BvAcxWXoV2eA+7Pfr+f\n2nXormC1bVd+A2x195+N+6eurJOZzTez2dnvlwBfotZB9Qrw9eywrqmPuz/i7kvd/XJqn5l/uPu3\n6NL6AJhZn5nNOv87cDewhS5tc+5+ENhnZldnoTuBt6m6Ph3oPLgH2E7tmuYPOt2Z0WAdngQOAGep\n/WV+gNo1zZeBd7PbOZ0uZx31+QK1/67/B3gj+7mnW+sEfB7YnNVnC/DDLH4FsAHYAfwZuLjTZW2g\nbl8Enu/2+mRlfzP7eet8LujWNpeVfRWwMWt3fwMGqq6PZoqKiCRCM0VFRBKhhC4ikggldBGRRCih\ni4gkQgldRCQRSugiIolQQhcRSYQSuohIIv4HbpAvSRhucMAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10612b240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from DataHelper import read_image\n",
    "training_images = np.array([ read_image(path) for path in image_paths] )\n",
    "\n",
    "print (\"training_images matrix shape\", training_images.shape)\n",
    "\n",
    "plt.imshow(training_images[2], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABsCAYAAAB6kUkRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSugiIpn4L10AVt5wY1n4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11af2ea20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_image \n",
      " (14, 64, 3) \n",
      " [[[-0.5       ]\n",
      "  [-0.5       ]\n",
      "  [-0.5       ]]\n",
      "\n",
      " [[-0.5       ]\n",
      "  [-0.49607843]\n",
      "  [-0.48431373]]\n",
      "\n",
      " [[-0.49607843]\n",
      "  [-0.5       ]\n",
      "  [-0.5       ]]]\n"
     ]
    }
   ],
   "source": [
    "from DataHelper import normalize_grayscale\n",
    "X_train = normalize_grayscale(training_images)\n",
    "sample_image = X_train[2]\n",
    "\n",
    "plt.imshow(sample_image, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "show_rows = 3\n",
    "show_cols = 3\n",
    "show_channels = 1\n",
    "\n",
    "print(\"sample_image \\n\", sample_image.shape,\"\\n\", sample_image[:show_rows,:show_cols,:show_channels]) #  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_single_channel \n",
      " [-0.5 -0.5 -0.5 -0.5 -0.5] <class 'numpy.ndarray'> (14, 64)\n"
     ]
    }
   ],
   "source": [
    "def extract_image_single_channel(image):\n",
    "    show_rows = image.shape[0]\n",
    "    show_cols = image.shape[1]\n",
    "    show_channels = 1 # red\n",
    "    return np.array(  image[:show_rows, :show_cols, 0] )\n",
    "\n",
    "image_single_channel = extract_image_single_channel(sample_image)\n",
    "print(\"image_single_channel \\n\", image_single_channel[0][:5], type(image_single_channel),image_single_channel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_features_normalized (6831, 14, 64, 3)\n",
      "single channel shape \n",
      " (6831, 14, 3)\n",
      "single channel column \n",
      " [[-0.5        -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5       ]\n",
      " [-0.47254902 -0.47254902 -0.47254902]\n",
      " [-0.5        -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5       ]\n",
      " [-0.47254902 -0.47254902 -0.47254902]\n",
      " [-0.5        -0.5        -0.5       ]\n",
      " [-0.48039216 -0.48039216 -0.48039216]\n",
      " [-0.5        -0.5        -0.5       ]\n",
      " [-0.46078431 -0.46078431 -0.46078431]\n",
      " [-0.13137255 -0.13137255 -0.13137255]\n",
      " [-0.40588235 -0.40588235 -0.40588235]\n",
      " [-0.5        -0.5        -0.5       ]\n",
      " [-0.47647059 -0.47647059 -0.47647059]]\n",
      "single channel pixel \n",
      " [-0.5 -0.5 -0.5]\n",
      "single channel red value \n",
      " -0.5\n",
      "single channel red value \n",
      " -0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"training_features_normalized\", X_train.shape)  \n",
    "\n",
    "X_train = extract_image_single_channel(X_train)\n",
    "\n",
    "print(\"single channel shape \\n\", X_train.shape)  \n",
    "print(\"single channel column \\n\", X_train[0:4][0]) \n",
    "print(\"single channel pixel \\n\", X_train[0][0]) \n",
    "print(\"single channel red value \\n\", X_train[0][0][0])  \n",
    "print(\"single channel red value \\n\", X_train[0][0][0])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Training labels (steering angle values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6831,)\n",
      "[ 0.          0.          0.04262284  0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "from DataHelper import get_steering_values, find_nearest\n",
    "steering_angles = get_steering_values(training) #array of float32\n",
    "print(steering_angles.shape)\n",
    "print(steering_angles[0:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Round steering angles\n",
    "\n",
    "- I might consider rounding the steering angles to lower amount of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_test = steering_angles # round(steering_angles, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "Y_train = np.array([], dtype=np.float32)\n",
    "\n",
    "for raw_label in steering_angles: # raw_labels[:5]\n",
    "    #print(\"raw_label\", raw_label)\n",
    "    rounded_value = float( find_nearest(steering_classes, raw_label) )\n",
    "    \n",
    "    # ???? Classification labels should be strings????\n",
    "    Y_train = np.append(X_test, [rounded_value])\n",
    "        \n",
    "print(X_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Encoding Training Labels in one-hot notation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "from DataHelper import sort_unique_floats, encode_one_hot\n",
    "\n",
    "sorted_unique_labels = sort_unique_floats(training_labels)\n",
    "print(\"sorted_unique_labels X\\n\",  sorted_unique_labels)\n",
    "y_one_hot = encode_one_hot(steering_classes, training_labels)\n",
    "print(y_one_hot[3])\n",
    "print(\"y_one_hot\", y_one_hot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Keras (with TensorFlow)\n",
    "\n",
    "https://keras.io/layers/convolutional/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import ELU\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Activation, Lambda\n",
    "\n",
    "from keras.activations import relu, softmax\n",
    "from keras.optimizers import SGD\n",
    "import cv2, numpy as np\n",
    "from DataHelper import mean_pred, false_rates\n",
    "\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D, Convolution1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### See Model_Keras_VGG_16.py\n",
    "\n",
    "This file (in the same directory) contains MODEL definiteion for VGG.16."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "#from Model_Keras_VGG_16 import build_model # model = build_model('vgg16_weights.h5')\n",
    "from keras.applications import vgg16\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "from keras.models import Model\n",
    "from DataHelper import show_layers\n",
    "\n",
    "model_VGG16 = VGG16(weights=None, include_top=True)\n",
    "\n",
    "model_VGG16.summary()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "number_of_layers = show_layers(model_VGG16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjust VGG.16 model architecture to match my needs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(\"number_of_layers\", number_of_layers)\n",
    "\n",
    "# create last layer with 21 classes\n",
    "#x = Dense(21, activation='softmax', name='predictions')(model_VGG16.layers[-2].output)\n",
    "\n",
    "# Convert to REGRESSION\n",
    "last_layer = model_VGG16.layers[number_of_layers-1]\n",
    "print(\"last_layer name\",last_layer.name)\n",
    "\n",
    "# One (1) output class makes this a (linear) regression.\n",
    "x22 = Dense(1, activation='linear', name='regression')(last_layer.output)\n",
    "model = Model(input=model_VGG16.input, output=x22)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from DataHelper import show_layers\n",
    "show_layers(model)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from keras.layers import InputLayer, Input\n",
    "\n",
    "#Layer (type)                     Output Shape          Param #     Connected to                     \n",
    "#input_3 (InputLayer)             (None, 224, 224, 3)   0  \n",
    "\n",
    "# model.add(Dense(32, input_dim=784))\n",
    "\n",
    "# Change layer #1\n",
    "\n",
    "\n",
    "my_input_shape = Input(shape=(14, 64, 1))\n",
    "# Input 0 is incompatible with layer block1_conv1: expected ndim=4, found ndim=5\n",
    "x = model_VGG16.get_layer(\"block1_conv1\")(my_input_shape)\n",
    "x = model_VGG16.get_layer(\"block1_conv2\")(x)\n",
    "x = model_VGG16.get_layer(\"block1_pool\")(x)\n",
    "\n",
    "x = model_VGG16.get_layer(\"block2_conv1\")(x)\n",
    "x = model_VGG16.get_layer(\"block2_conv2\")(x)\n",
    "x = model_VGG16.get_layer(\"block2_pool\")(x)\n",
    "\n",
    "x = model_VGG16.get_layer(\"block3_conv1\")(x)\n",
    "x = model_VGG16.get_layer(\"block3_conv2\")(x)\n",
    "x = model_VGG16.get_layer(\"block3_conv3\")(x)\n",
    "x = model_VGG16.get_layer(\"block3_pool\")(x)\n",
    "\n",
    "x = model_VGG16.get_layer(\"block4_conv1\")(x)\n",
    "x = model_VGG16.get_layer(\"block4_conv2\")(x)\n",
    "x = model_VGG16.get_layer(\"block4_conv3\")(x)\n",
    "x = model_VGG16.get_layer(\"block4_pool\")(x)\n",
    "\n",
    "x = model_VGG16.get_layer(\"block5_conv1\")(x)\n",
    "x = model_VGG16.get_layer(\"block5_conv2\")(x)\n",
    "x = model_VGG16.get_layer(\"block5_conv3\")(x)\n",
    "x = model_VGG16.get_layer(\"block5_pool\")(x)\n",
    "\n",
    "x = model_VGG16.get_layer(\"flatten\")(x)\n",
    "x = model_VGG16.get_layer(\"fc1\")(x)\n",
    "x = model_VGG16.get_layer(\"fc2\")(x)\n",
    "x = model_VGG16.get_layer(\"predictions\")(x)\n",
    "result = model_VGG16.get_layer(\"regression\")(x)\n",
    "\n",
    "model = Model(input=my_input_shape, output=result)\n",
    "\n",
    "#intput_layer = model_VGG16.layers[0]\n",
    "#print(\"intput_layer name\", intput_layer.name)\n",
    "\n",
    "\n",
    "#L0 = InputLayer((None, 14, 64, 1), name='input_14x64x1')(intput_layer.output)\n",
    "#model = Model(input=model_VGG16.input, output=L0)\n",
    "\n",
    "model.summary() \n",
    "show_layers(model)\n",
    "\n",
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 14, 64, 64)    1792        convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "regression_result (Dense)        (None, 14, 64, 1)     65          convolution2d_1[0][0]            \n",
      "====================================================================================================\n",
      "Total params: 1,857\n",
      "Trainable params: 1,857\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import InputLayer, Input\n",
    "\n",
    "model = Sequential()\n",
    "# apply a 3x3 convolution with 64 output filters on a 14x64 image:\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', \n",
    "                        input_shape=(14, 64 ,3), dim_ordering='tf'))\n",
    "# now model.output_shape == (None, 64, 14, 64)\n",
    "#model.add(Activation('relu', name=\"02_ReLU\"))\n",
    "#model.add(Convolution2D(32, 3, 3, border_mode='same', name=\"03_conv\"))\n",
    "#model.add(Activation('relu', name=\"04_ReLU\"))\n",
    "\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "#The shape of the input to \"Flatten\" is not fully defined (got (None, 14, 32). \n",
    "#Make sure to pass a complete \"input_shape\" or \"batch_input_shape\" argument to the first layer in your model.\n",
    "#The shape of the input to \"Flatten\" is not fully defined (got (None, 7, 32). \n",
    "#Make sure to pass a complete \"input_shape\" or \"batch_input_shape\" argument to the first layer in your model.\n",
    "#model.add(Flatten())\n",
    "\n",
    "#Negative dimension size caused by subtracting 2 from 1 for 'MaxPool_15' (op: 'MaxPool') with input shapes: [?,1,14,32].\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "#model.add(Dense(256))\n",
    "#model.add(Activation('relu', name=\"04_ReLU\"))\n",
    "#model.add(Dense(256))\n",
    "#model.add(Activation('relu'))\n",
    "\n",
    "#expected regression to have 4 dimensions, but got array with shape (6831, 21)\n",
    "model.add(Dense(1, activation='linear', name='regression_result'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile model (configure learning process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Before training a model, you need to configure the learning process, which is done via the compile method.\n",
    "optimizer='sgd' # | 'rmsprop'\n",
    "loss_function='mean_squared_error' # | 'binary_crossentropy' | 'mse'\n",
    "metrics_array=['accuracy'] # , mean_pred, false_rates\n",
    "\n",
    "model.compile(optimizer, loss_function, metrics_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace model with one stored on disk\n",
    "\n",
    "- If you replace the model, the INPUT dimetions have to be the same as these trained\n",
    "- Name your models well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "#model = load_model('model.h5') # pick model to resume\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train (fit) the model agaist given labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-9286d2abb548>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(X_train, Y_train, nb_epoch=3, \n\u001b[0m\u001b[1;32m      2\u001b[0m                     batch_size=batch_size, verbose=1, show_accuracy=True, validation_split=0.2)\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#history = model.fit(training_features_normalized, raw_labels, nb_epoch=3, verbose=1, validation_split=0.2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#history = model.fit(training_features_normalized, training_labels, nb_epoch=3, verbose=1, validation_split=0.2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Y_train' is not defined"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, nb_epoch=3, \n",
    "                    batch_size=batch_size, verbose=1, show_accuracy=True, validation_split=0.2)\n",
    "\n",
    "#history = model.fit(training_features_normalized, raw_labels, nb_epoch=3, verbose=1, validation_split=0.2)\n",
    "#history = model.fit(training_features_normalized, training_labels, nb_epoch=3, verbose=1, validation_split=0.2)\n",
    "#history = model.fit(training_features_normalized, y_one_hot, nb_epoch=run_epochs, validation_split=0.2)\n",
    "#history = model.fit(single_channel_features, y_one_hot, nb_epoch=run_epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Epoch 20/20 loss: 0.0518 - acc: 0.60 - val_loss: 0.05 - val_acc: 0.59\n",
    "\n",
    "Train on 5464 samples, validate on 1367 samples\n",
    "Epoch 1/2\n",
    "5440/5464 [============================>.] - ETA: 42s - loss: 0.0453 - acc: 0.6099"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "training_accuracy = str( history.history['acc'][run_epochs-1])\n",
    "print(\"training_accuracy\", training_accuracy)\n",
    "\n",
    "training_error = str( history.history['loss'][run_epochs-1])\n",
    "print(\"training_error\", training_error)\n",
    "\n",
    "\n",
    "validation_accuracy = str( history.history['val_acc'][run_epochs-1])\n",
    "print(\"validation_accuracy\", validation_accuracy)\n",
    "\n",
    "validation_error = str( history.history['val_loss'][run_epochs-1])\n",
    "print(\"validation_error\", validation_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.save(data_dir + \"MODELS/\" + model_name + training_accuracy + \".h5') # creates a HDF5 file '___.h5'\n",
    "#del model  # deletes the existing model\n",
    "#model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy (bigger better)')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training accuracy', 'testing accuracy'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Validation error (smaller better)')\n",
    "plt.ylabel('error')\n",
    "plt.xlabel('epochs run')\n",
    "plt.legend(['training error', 'testing error'], loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda env carnd-term1",
   "language": "python",
   "name": "carnd-term1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
