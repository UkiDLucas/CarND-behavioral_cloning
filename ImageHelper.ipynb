{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import base64\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import eventlet\n",
    "import eventlet.wsgi\n",
    "import tensorflow as tf\n",
    "import socketio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "from flask import Flask, render_template\n",
    "from io import BytesIO\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from numpy import array\n",
    "import random\n",
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define RGB colors used in the code\n",
    "RED = color=[255, 0, 0]\n",
    "GREEN = color=[0, 255, 0]\n",
    "BLUE = color=[0, 0, 255]\n",
    "WHITE = color=[255, 255, 255]\n",
    "GRAY = color=[192, 192, 192]\n",
    "VIOLET = color=[153, 51, 255]\n",
    "ORANGE = color=[255, 128, 0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Read image from the disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def read_image_binary(image_path):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    <class 'PIL.JpegImagePlugin.JpegImageFile'>\n",
    "    \"\"\"\n",
    "    from PIL import Image\n",
    "    image = Image.open(image_path)\n",
    "    return image\n",
    "\n",
    "def read_image_array(image_path):\n",
    "    import cv2\n",
    "    # cv2.IMREAD_COLOR \n",
    "    # cv2.COLOR_BGR2GRAY \n",
    "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    #print(\"image shape\", image.shape)\n",
    "    #plt.imshow(image, cmap='gray')\n",
    "    #plt.show()\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import PIL\n",
    "import numpy\n",
    "from PIL import Image\n",
    "\n",
    "def resize_image_maintain_ratio(numpy_array_image, new_size):\n",
    "    \"\"\"\n",
    "    I am NOT zero-padding at this moment, \n",
    "    just resizing for the longest size is equal to new_size.\n",
    "    The zero-padding can effectively by done later,\n",
    "    for example during machine learning.\n",
    "    There is no point of wasting space with\n",
    "    thens of thousands padded padded images. \n",
    "    \"\"\"\n",
    "    # convert nympy array image to PIL.Image\n",
    "    image = Image.fromarray(numpy.uint8(numpy_array_image))\n",
    "    old_width = float(image.size[0])\n",
    "    old_height = float(image.size[1])\n",
    "    \n",
    "    if old_width > old_height:\n",
    "        # by width since it is longer\n",
    "        new_width = new_size\n",
    "        ratio = float(new_width / old_width)\n",
    "        new_height = int(old_height * ratio)\n",
    "    else:\n",
    "        # by height since it is longer\n",
    "        new_width = new_size\n",
    "        ratio = float(new_width / old_width)\n",
    "        new_height = int(old_height * ratio)\n",
    "        \n",
    "    image = image.resize((new_width, new_height), PIL.Image.ANTIALIAS)\n",
    "    # turn image into nympy array again\n",
    "    return array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def mask_vertices(image):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "\n",
    "    top_left = (width*0.3, 0)\n",
    "    top_right = (width-width*0.3, 0)\n",
    "     \n",
    "    mid_left_high = (0, height*0.2) \n",
    "    mid_right_high = (width, height*0.2)  \n",
    "    \n",
    "    mid_left_low = (0, height*0.9) \n",
    "    mid_right_low = (width, height*0.9)\n",
    "    \n",
    "    # on the bottom start high because of the dashboard\n",
    "    bottom_center_left = (width*0.27, height*0.95) \n",
    "    bottom_center_right = (width-width*0.27, height*0.95) \n",
    "    \n",
    "    # we are NOT following a center line in this code, so cut it out\n",
    "    bottom_center = (width/2, height*0.55) \n",
    "\n",
    "\n",
    "    # add points clockwise\n",
    "    vertices = np.array([[\n",
    "        top_left, \n",
    "        top_right, \n",
    "        mid_right_high, mid_right_low,\n",
    "        bottom_center_right,\n",
    "        bottom_center, bottom_center_left,\n",
    "        mid_left_low, \n",
    "        mid_left_high \n",
    "    ]], dtype=np.int32)\n",
    "    return vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def canny(image, low_threshold=50, high_threshold=250): \n",
    "    # homework low_threshold=20, high_threshold=130\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(image, low_threshold, high_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def gaussian_blur(image, kernel_size=5): # 5 \n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "def grayscale(image):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "    This will return an image with only one color channel\n",
    "    but NOTE: to see the returned image as grayscale\n",
    "    you should call plt.imshow(gray, cmap='gray')\"\"\"\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    # Or use BGR2GRAY if you read an image with cv2.imread()\n",
    "    # return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def crop_image(image):\n",
    "    left = 0\n",
    "    upper = 70\n",
    "    right = 320\n",
    "    lower = 140 # 160 original\n",
    "    image = image.crop((left, upper, right, lower))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    " def print_image(image, should_plot, comment=\"my image\"):\n",
    "    if should_plot:\n",
    "        print(comment, array(image).shape)\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def normalize_grayscale(image_data):\n",
    "    a = -0.5\n",
    "    b = 0.5\n",
    "    grayscale_min = 0\n",
    "    grayscale_max = 255\n",
    "    return a + ( ( (image_data - grayscale_min)*(b - a) )/( grayscale_max - grayscale_min ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def round_int(x):\n",
    "    if x == float(\"inf\") or x == float(\"-inf\"):\n",
    "        # return float('nan') # or x or return whatever makes sense\n",
    "        return 1000\n",
    "    return int(round(x))\n",
    "\n",
    "def test_round_int():\n",
    "    print(round_int(174.919753086))\n",
    "    print(round_int(0))\n",
    "    print(round_int(float(\"inf\")))\n",
    "    print(round_int(float(\"-inf\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_x(slope, y, y_intercept):\n",
    "    \n",
    "    if math.isnan(slope): # vertical line cannot have a slope\n",
    "        return float('nan')\n",
    "    if slope == float('Inf') or slope == -float('Inf'):\n",
    "        return float('nan')\n",
    "    if y_intercept == float('Inf') or y_intercept == -float('Inf'):\n",
    "        return float('nan')\n",
    "    \n",
    "    result = 0 # temp\n",
    "    try:\n",
    "        if slope == 0: # flat line\n",
    "            slope = 0.01 # avoid division by zero, result will be a large number, almost flat line\n",
    "        x = (y - y_intercept)/slope\n",
    "        result = round_int(x)\n",
    "    except ValueError:\n",
    "        print(\"ValueError: calc_x That was no valid number.  slope\", slope, \"y\", y, \"y_intercept\", y_intercept)\n",
    "    return   result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_y_intercept(slope, x, y):\n",
    "    return y - (x * slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_slope(x1, y1, x2, y2):        \n",
    "    rise = y2 - y1\n",
    "    \n",
    "    run = x2 - x1\n",
    "    try:\n",
    "        slope = rise/run\n",
    "        return slope\n",
    "    except ZeroDivisionError:\n",
    "        print(\"ZeroDivisionError: calc_slope the slope cannot be calculated for a VERTICAL LINE.\")\n",
    "    \n",
    "\n",
    "# TEST\n",
    "#print(calc_slope(-1, 2, 1, 3))\n",
    "#print(calc_slope(2, 2, 1, 3))\n",
    "#print(calc_slope(1, 2, 1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def side(image, line):\n",
    "    \"\"\"\n",
    "    This function determines if line\n",
    "    should be procesed as \"left\", \"right\"\n",
    "    or rejected entirely as irrelevant.\n",
    "\n",
    "    side: LEFT, slope -0.923076923077\n",
    "    side: RIGHT, slope 0.65\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    width = image.shape[1] # right of the image frame\n",
    "    height = image.shape[0] # bottom of the image frame\n",
    "\n",
    "    for x1,y1,x2,y2 in arrangeLineCoordinates(line):\n",
    "        slope = calc_slope(x1,y1,x2,y2)\n",
    "        intercept = calc_y_intercept(slope, x1, y1)\n",
    "        # I am interested where is x (left, or right)\n",
    "        # if you extend the line to the bottom of the image\n",
    "        y2 = height\n",
    "        x2 = calc_x(slope, y2 , intercept) \n",
    "\n",
    "        if (x2 < width/2 - width*0.1) and (-0.95 < slope < -0.15) : # LEFT negative\n",
    "            return \"left\"\n",
    "        elif  (width/2 + width*0.1 < x2 ) and (0.95 > slope > 0.15): # RIGHT positive\n",
    "            # print(\"side: RIGHT, slope\", slope)\n",
    "            return \"right\"\n",
    "        else:\n",
    "            # print(\"irrelevant, slope\", slope, \"x2\", x2)\n",
    "            return \"irrelevant\" # the line extends off screen, to be tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def arrangeLineCoordinates(line):\n",
    "    \"\"\"\n",
    "    This method enforces that given line,\n",
    "    has x1, y1 on TOP\n",
    "    and x2, y2 on the BOTTOM of the image.\n",
    "    \n",
    "    It is user responsibility to test\n",
    "    if line is a valid object.\n",
    "    I have no way to know what to return otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            if y1 > y2:\n",
    "                # print(\"WARNING y1 > y2 swapping the order\")\n",
    "                temp_x2 = x1\n",
    "                temp_y2 = y1\n",
    "                temp_x1 = x2\n",
    "                temp_y1 = y2\n",
    "\n",
    "                x1 = temp_x1\n",
    "                x2 = temp_x2\n",
    "                y1 = temp_y1\n",
    "                y2 = temp_y2   \n",
    "                line = np.array([[x1, y1, x2, y2]], np.int32)\n",
    "    except ValueError:\n",
    "        #print(\"Provided line has unexpected values\", line)\n",
    "        line = np.array([[0, 0, 0, 0]], np.int32)\n",
    "    except TypeError:\n",
    "        # Use this as visual clue that line is not correct\n",
    "        #print(\"Provided line has unexpected type\", type(line))\n",
    "        line = np.array([[0, 0, 0, 0]], np.int32)\n",
    "                \n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def draw_lines(image, lines, color=WHITE, thickness=1):\n",
    "    \"\"\"   \n",
    "    Lines are drown over the image, i.e. mutates the image.\n",
    "    If you want to make the lines semi-transparent, think about combining\n",
    "    this function with the weighted_img() function below\n",
    "    \"\"\"\n",
    "    if lines is not None: # no point processing is no lines were found\n",
    "        for line in lines:\n",
    "            try:\n",
    "                if line is not None: # TypeError: 'NoneType' object is not iterable\n",
    "                    line = arrangeLineCoordinates(line)\n",
    "                    for x1,y1,x2,y2 in line:\n",
    "                        cv2.line(image, (x1, y1), (x2, y2), color, thickness)\n",
    "            except ValueError:\n",
    "                #print(\"Oops!  draw_lines\", line)\n",
    "                cv2.line(image, (0, 0), (0, 0), color, thickness)\n",
    "            except TypeError:\n",
    "                #print(\"Oops!  draw_lines\", line)\n",
    "                cv2.line(image, (0, 0), (0, 0), color, thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hough_lines(image, rho=2, theta=np.pi/180, threshold=20, min_line_len=10, max_line_gap=5):\n",
    "    \"\"\"\n",
    "    - rho ρ is the distance from the origin\n",
    "    - theta θ is the angle\n",
    "    - min_line_len minimum length of a line that will be created\n",
    "    - max_line_gap maximum distance between segments that will be connected to a single line\n",
    "    - threshold increasing(~ 50-60) will rule out the spurious lines.\n",
    "    defines the minimum number of intersections in a given grid cell that are required to choose a line.)\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(image, rho, theta, threshold, np.array([]), \n",
    "                            minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    if lines is None: # no point processing if no lines were found\n",
    "        return image\n",
    "    \n",
    "    width = image.shape[1] # right of the image frame\n",
    "    height = image.shape[0] # bottom of the image frame\n",
    "\n",
    "    left_longest_line = 0\n",
    "    right_longest_line = 0\n",
    "\n",
    "    relevant_hough_lines_left = [] \n",
    "    relevant_hough_lines_right = [] \n",
    "    rejected_hough_lines = []\n",
    "    longest_lines_left = []\n",
    "    longest_lines_right = []\n",
    "\n",
    "    longest_right = 0\n",
    "    longest_left = 0\n",
    "\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in arrangeLineCoordinates(line):\n",
    "\n",
    "            # get vertical HEIGHT of this line \n",
    "            y_difference = abs(y2 - y1)\n",
    "\n",
    "            # Categorize the lines to LEFT | RIGHT \n",
    "            side_detected = side(image, line)\n",
    "            \n",
    "            if \"left\" == side_detected:\n",
    "                relevant_hough_lines_left.append(line)\n",
    "                if y_difference > longest_left:\n",
    "                    left_longest_line = line\n",
    "                    longest_left = y_difference\n",
    "                    \n",
    "            elif  \"right\" == side_detected:\n",
    "                relevant_hough_lines_right.append(line)\n",
    "                if y_difference > longest_right:\n",
    "                    right_longest_line = line\n",
    "                    longest_right = y_difference\n",
    "\n",
    "            else:\n",
    "                rejected_hough_lines.append(line) # WHITE\n",
    "\n",
    "    longest_lines_left.append(left_longest_line)  # ORANGE \n",
    "    longest_lines_right.append(right_longest_line) # ORANGE \n",
    "    \n",
    "    # draw a blank black image\n",
    "    image_lines = np.zeros((image.shape[0], image.shape[1], 3), dtype=np.uint8)\n",
    "    \n",
    "    # draw color-coded HOUGH lines\n",
    "    # Most of the time I do not want to draw all of the WHITE lines   \n",
    "    #draw_lines(image_lines, lines, color=WHITE, thickness=2)\n",
    "    draw_lines(image_lines, relevant_hough_lines_left, color=RED, thickness=1)\n",
    "    draw_lines(image_lines, relevant_hough_lines_right, color=GREEN, thickness=1)\n",
    "\n",
    "    return image_lines\n",
    "\n",
    "\n",
    "# TEST  \n",
    "#image_hough_lines = hough_lines(image_mask)\n",
    "#plt.imshow(image_hough_lines)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "#image_hough_lines = hough_lines(image_mask, rho=2, theta=np.pi/180, threshold=25, min_line_len=25, max_line_gap=20)\n",
    "#plt.imshow(image_hough_lines)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def preprocessing_pipline(image, final_size=512, should_plot=False):\n",
    "    \"\"\"\n",
    "    final_size=256 AlexNet and GoogLeNet\n",
    "    final_size=224 VGG-16\n",
    "    final_size=64  is OPTIMAL if I was writing CDNN from scratch\n",
    "    final_size=32  images are fuzzy, AlexNet (street signs CDNN)\n",
    "    final_size=28  images are very fuzzy, LeNet\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "        \n",
    "    image = array(crop_image(image)) # 'numpy.ndarray' object has no attribute 'crop'\n",
    "    print_image(image, should_plot, comment=\"my image\")\n",
    "\n",
    "    #image = region_of_interest(image, mask_vertices(image))\n",
    "    #print_image(comment=\"grayscale\", image, should_plot)\n",
    "    \n",
    "    image = grayscale(image)\n",
    "    print_image(image, should_plot, comment=\"grayscale\")\n",
    "\n",
    "    image = gaussian_blur(image, kernel_size=5)\n",
    "    print_image(image, should_plot, comment=\"gaussian_blur\")\n",
    "    \n",
    "    image = canny(image, low_threshold=100, high_threshold=190)\n",
    "    print_image(image, should_plot, comment=\"canny\")\n",
    "    \n",
    "    image = hough_lines(image)\n",
    "    print_image(image, should_plot, comment=\"hough_lines\")\n",
    "    \n",
    "    image = resize_image_maintain_ratio(image, new_size=final_size)\n",
    "    print_image(image, should_plot, comment=\"resize_image_maintain_ratio\")\n",
    "\n",
    "        \n",
    "    image = normalize_grayscale(image)\n",
    "    print_image(image, should_plot, comment=\"normalize_grayscale\")\n",
    "\n",
    "    return image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda env carnd-term1",
   "language": "python",
   "name": "carnd-term1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
