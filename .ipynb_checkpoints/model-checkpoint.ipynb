{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training UkiNet model\n",
    "\n",
    "Please refer to README file for project overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"../../../DATA/behavioral_cloning_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.image as mpimg\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported rows 8037\n"
     ]
    }
   ],
   "source": [
    "import DataHelper\n",
    "#print(DataHelper.__doc__)\n",
    "from DataHelper import test_read_csv, read_csv\n",
    "#print(read_csv.__doc__)\n",
    "#test_read_csv()\n",
    "# fetch actual log of driving data\n",
    "headers, data = read_csv(data_dir + \"driving_log.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labels (steering value classes)\n",
    "\n",
    "- Please review notebook \"preprocessing\", section: \"Steering value distribution\".\n",
    "- Training labels have values ranging from -1 to +1.\n",
    "- When you steer with **keyboard** the STEPS are rather corse, so I think I can get away with **discrete steering angles, i.e. classes**.\n",
    "- I will start training with 21 equally spread classes, if needed I will increase to 41.\n",
    "- I want to make sure that my classes include **0.0 (zero)** as it is most common value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering_classes [-1.  -0.9 -0.8 -0.7 -0.6 -0.5 -0.4 -0.3 -0.2 -0.1  0.   0.1  0.2  0.3  0.4\n",
      "  0.5  0.6  0.7  0.8  0.9  1. ]\n",
      "Number of classes 21\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEWCAYAAACaBstRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuXHxEEcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11400f7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "number_of_classes = 21\n",
    "steering_classes = np.linspace(-1, 1, num=number_of_classes, endpoint=True) \n",
    "steering_classes = np.sort(steering_classes)\n",
    "print(\"steering_classes\", steering_classes)\n",
    "print(\"Number of classes\",steering_classes.shape[0])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(steering_classes, 'b.')\n",
    "plt.margins(0.1)\n",
    "plt.title(\"Distribution of steering value classes.\")\n",
    "plt.xlabel(\"class number\")\n",
    "plt.ylabel('steering value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Split data into training, testing and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent_validation 15\n",
      "training (5626, 7)\n",
      "testing (1206, 7)\n",
      "validation (1204, 7)\n"
     ]
    }
   ],
   "source": [
    "from DataHelper import split_random, get_image_center_values\n",
    "image_center_values = get_image_center_values(data)\n",
    "\n",
    "training, testing, validation = \\\n",
    "split_random(data, percent_train=70, percent_test=15) \n",
    "\n",
    "print(\"training\",training.shape)\n",
    "print(\"testing\",testing.shape)\n",
    "print(\"validation\",validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract training features (images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5626,)\n",
      "IMG/center_2016_12_01_13_37_23_978.jpg\n"
     ]
    }
   ],
   "source": [
    "from DataHelper import get_image_center_values \n",
    "image_names = get_image_center_values(training)\n",
    "print(image_names.shape)\n",
    "print(image_names[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a list of image paths pointing to 64px version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../DATA/behavioral_cloning_data/processed_images_64/IMG/center_2016_12_01_13_37_23_978.jpg\n"
     ]
    }
   ],
   "source": [
    "image_paths = []\n",
    "for image_name in image_names:\n",
    "    image_paths.extend([data_dir + \"processed_images_64/\" + image_name])\n",
    "print(image_paths[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0dbe6f464325>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mDataHelper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtraining_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mread_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"matrix shape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-0dbe6f464325>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mDataHelper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtraining_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mread_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"matrix shape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ukilucas/dev/carnd/p3_behavioral_cloning/behavioral_cloning_UkiDLucas/DataHelper.py\u001b[0m in \u001b[0;36mread_image\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# cv2.IMREAD_COLOR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;31m# cv2.COLOR_BGR2GRAY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0;31m#print(\"image shape\", image.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m#plt.imshow(image, cmap='gray')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "from DataHelper import read_image\n",
    "training_features = np.array([ read_image(path) for path in image_paths] )\n",
    "\n",
    "print (\"matrix shape\", training_features.shape)\n",
    "plt.imshow(training_features[2], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blank_image = np.zeros((14, 64, 2), dtype=np.float64)\n",
    "\n",
    "from random import randrange, uniform\n",
    "random_index = 1# randrange(0, 5626) \n",
    " \n",
    "print(\"training_features shape\", training_features.shape)\n",
    "image = training_features[random_index]\n",
    "#print(image[0,0,:])\n",
    "print(\"training_feature shape\", image.shape)\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "print(\"training_feature \\n\", image)\n",
    "\n",
    "modifield = np.append(image, blank_image)\n",
    "print(\"modifield\", modifield.shape)\n",
    "plt.imshow(modifieldv)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_grayscale(image_data):\n",
    "    a = -0.5\n",
    "    b = 0.5\n",
    "    grayscale_min = 0\n",
    "    grayscale_max = 255\n",
    "    return a + ( ( (image_data - grayscale_min)*(b - a) )/( grayscale_max - grayscale_min ) )\n",
    "\n",
    "training_features_normalized = normalize_grayscale(training_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract training labels (steering value classes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from DataHelper import get_steering_values, find_nearest\n",
    "raw_labels = get_steering_values(training)\n",
    "print(raw_labels.shape)\n",
    "print(raw_labels[0:5])\n",
    "\n",
    "training_labels = np.array([], dtype=np.float64)\n",
    "\n",
    "for raw_label in raw_labels: # raw_labels[:5]\n",
    "    #print(\"raw_label\", raw_label)\n",
    "    label = find_nearest(steering_classes, raw_label)\n",
    "    #print(\"normalized label\", label)\n",
    "    \n",
    "    # Classification labels should be strings:\n",
    "    training_labels = np.append(training_labels, [str(label)])\n",
    "        \n",
    "print(training_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_one_hot = label_binarizer.fit_transform(training_labels)\n",
    "print(y_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Extract "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras (with TensorFlow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Activation\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.activations import relu, softmax\n",
    "from keras.optimizers import SGD\n",
    "import cv2, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "#model.add(ZeroPadding2D((1,1)))\n",
    "#model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "#model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "#model.add(ZeroPadding2D((1,1)))\n",
    "#model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "#model.add(ZeroPadding2D((1,1)))\n",
    "#model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "#model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "#model.add(ZeroPadding2D((1,1)))\n",
    "#model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "#model.add(ZeroPadding2D((1,1)))\n",
    "#model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "#model.add(ZeroPadding2D((1,1)))\n",
    "#model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "#model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "#model.add(ZeroPadding2D((1,1)))\n",
    "#model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "#model.add(ZeroPadding2D((1,1)))\n",
    "#model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "#model.add(ZeroPadding2D((1,1)))\n",
    "#model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "#model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "#model.add(ZeroPadding2D((1,1)))\n",
    "#model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "#model.add(ZeroPadding2D((1,1)))\n",
    "#model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "#model.add(ZeroPadding2D((1,1)))\n",
    "#model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "#model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "    \n",
    "def UkiNet(weights_path=None):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # original images are (3, 14, 64) need to square them\n",
    "    # Exception: Error when checking model input: \n",
    "            # expected zeropadding2d_input_1 to have 4 dimensions, \n",
    "            # but got array with shape (5626, 14, 64)\n",
    "            # model.add(ZeroPadding2D((1,1),input_shape=(3,64,64))\n",
    " \n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(1,64,64)))\n",
    "    # Might be redundant, but assure the size 64x64\n",
    "    model.add(Flatten(input_shape=(64, 64, 3)))\n",
    "    \n",
    "    model.add(Dense(128)) # Fully connected \n",
    "    model.add(Activation('relu')) # ReLU activation\n",
    "    model.add(Dense(43))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "\n",
    "\n",
    "    #Input 0 is incompatible with layer flatten_7: expected ndim >= 3, found ndim=2\n",
    "    #model.add(Flatten())\n",
    "    #model.add(Dense(4096, activation='relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    #model.add(Dense(4096, activation='relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    \n",
    "    # I want to end up with 21 classes\n",
    "    model.add(Dense(21, activation='softmax'))\n",
    "\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "    return model\n",
    "\n",
    "model = UkiNet()\n",
    "# Configures the learning process and metrics\n",
    "model.compile('sgd', 'mean_squared_error', ['accuracy'])\n",
    "history = model.fit(training_features_normalized, y_one_hot, nb_epoch=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_layers(layers, true_layers):\n",
    "    assert len(true_layers) != 0, 'No layers found'\n",
    "    for layer_i in range(len(layers)):\n",
    "        assert isinstance(true_layers[layer_i], layers[layer_i]), \\\n",
    "        'Layer {} is not a {} layer'.format(layer_i+1, layers[layer_i].__name__)\n",
    "        \n",
    "    assert len(true_layers) == len(layers), \\\n",
    "    '{} layers found, should be {} layers'.format(len(true_layers), len(layers))\n",
    "\n",
    "check_layers([Flatten, Dense, Activation, Dense, Activation], model.layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda env tensorflow_cpu",
   "language": "python",
   "name": "tensorflow_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
