{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# How to run the simulator\n",
    "$ python drive.py model.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"../../../DATA/behavioral_cloning_data/\"\n",
    "model_dir = \"../../../DATA/MODELS/\"\n",
    "model_name = \"model_p3_keras_tf_mini_14x64x3__epoch_40_val_loss_0.0198594339299.h5\"\n",
    "image_final_width = 64\n",
    "model_path = model_dir + model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import base64\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import eventlet\n",
    "import eventlet.wsgi\n",
    "import tensorflow as tf\n",
    "import socketio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "from flask import Flask, render_template\n",
    "from io import BytesIO\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array\n",
    "\n",
    "# if says Using Theano backend.\n",
    "# $ edit ~/.keras/keras.json\n",
    "# change to: \"backend\": \"tensorflow\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/fchollet/keras/issues/3857\n",
    "tf.python.control_flow_ops = tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from DataHelper import create_steering_classes\n",
    "steering_classes = create_steering_classes(number_of_classes = 41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_and_compile_model():\n",
    "    from keras.models import load_model\n",
    "    model = load_model(model_path) # should start at 60% acc.\n",
    "    optimizer='sgd' # | 'rmsprop'\n",
    "    loss_function='mean_squared_error' # | 'binary_crossentropy' | 'mse'\n",
    "    metrics_array=['accuracy'] # , mean_pred, false_rates\n",
    "    model.compile(optimizer, loss_function, metrics_array)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 14, 64, 64)    1792        convolution2d_input_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 14, 64, 128)   73856       convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 14, 64, 256)   295168      convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 229376)        0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 256)           58720512    flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 256)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 256)           65792       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 41)            10537       dense_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 59,167,657\n",
      "Trainable params: 59,167,657\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_and_compile_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def predict_steering(image, old_steering):\n",
    "    image = np.array(image)\n",
    "    image = image[None, :, :] # string indices must be integers\n",
    "    predictions = float(model.predict(image))\n",
    "    print(\"predictions\", predictions)\n",
    "    #prediction = float(predictions[0][0])\n",
    "    #most_likely = np.argmax(predictions)\n",
    "    print(\"most_likely\", most_likely)\n",
    "    new_steering_angle = steering_classes[most_likely]\n",
    "    print(\"new_steering_angle\", new_steering_angle)\n",
    "    return new_steering_angle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape (14, 64)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABsCAYAAAB6kUkRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhMSE/wUgXcr+BOYdsAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1212978d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "autonomous_run_image = \"autonomous_run/image_14.31785798072815.jpg\"\n",
    "from DataHelper import load_image\n",
    "image_path = data_dir + autonomous_run_image\n",
    "image = np.array(load_image(image_path))\n",
    "print(\"image shape\", image.shape)\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected convolution2d_input_2 to have 4 dimensions, but got array with shape (1, 14, 64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-bf6ebaf0d532>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_steering_angle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_steering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"new_steering_angle\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_steering_angle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-1fb26b70ef4f>\u001b[0m in \u001b[0;36mpredict_steering\u001b[0;34m(image, old_steering)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# string indices must be integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"predictions\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#prediction = float(predictions[0][0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ukilucas/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ukilucas/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1253\u001b[0m         x = standardize_input_data(x, self.input_names,\n\u001b[1;32m   1254\u001b[0m                                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m                                    check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1256\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ukilucas/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    110\u001b[0m                                  \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                                  \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                                  str(array.shape))\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking : expected convolution2d_input_2 to have 4 dimensions, but got array with shape (1, 14, 64)"
     ]
    }
   ],
   "source": [
    "new_steering_angle = predict_steering(image, 0.0)\n",
    "print(\"new_steering_angle\", new_steering_angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image_string, elapsed_seconds):   \n",
    "    \n",
    "    from scipy.misc import imsave\n",
    "    from ImageHelper import preprocessing_pipline\n",
    "    \n",
    "    image_jpg = Image.open(BytesIO(base64.b64decode(image_string)))\n",
    "    image_array = preprocessing_pipline(image_jpg, final_size=image_final_width, should_plot=False)\n",
    "    \n",
    "    from DataHelper import normalize_grayscale\n",
    "    image_array = normalize_grayscale(image_array)\n",
    "    \n",
    "    # saving only to review that pre-processing worked\n",
    "    imsave(data_dir + \"autonomous_run/image_\" + str(elapsed_seconds) + \".jpg\", image_array)\n",
    "    return image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#    model = VGG_16('vgg16_weights.h5')\n",
    "#   sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#    model.compile(optimizer=sgd, loss='categorical_crossentropy')\n",
    "#    out = model.predict(im)\n",
    "#    print np.argmax(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sio = socketio.Server()\n",
    "app = Flask(__name__)\n",
    "model = None\n",
    "prev_image_array = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "@sio.on('telemetry')\n",
    "def telemetry(sid, data):\n",
    "    with open(\"output.txt\", \"a\") as myfile:\n",
    "        elapsed_seconds = time.time()-t0\n",
    "        \n",
    "        # The current steering angle of the car\n",
    "        steering_angle = data[\"steering_angle\"]\n",
    "        \n",
    "        # The current throttle of the car\n",
    "        throttle = data[\"throttle\"]\n",
    "        \n",
    "        # The current speed of the car\n",
    "        speed = data[\"speed\"]\n",
    "\n",
    "        # The current image from the center camera of the car\n",
    "        image = preprocess_image(data[\"image\"], elapsed_seconds)\n",
    "\n",
    "        new_steering_angle = predict_steering(image, steering_angle)\n",
    "        new_throttle = 0.3\n",
    "        \n",
    "        output = []\n",
    "        output.append(str(round(float(elapsed_seconds),2)) + \"\\t\")\n",
    "        output.append(str(round(float(speed),2)) + \"\\t\")\n",
    "        output.append(str(round(float(steering_angle),2)) +\"->\")\n",
    "        output.append(str(round(float(new_steering_angle),2)) +\"\\t\" )\n",
    "        output.append(str(round(float(throttle),2)) +\"->\" )\n",
    "        output.append(str(round(float(new_throttle),2)) + \"\\n\" )\n",
    "        output_text = ''.join(output)\n",
    "        myfile.write(output_text)\n",
    "        #print(output_text)\n",
    "        \n",
    "        send_control(new_steering_angle, new_throttle)\n",
    "\n",
    "# $ tail -f ~/dev/carnd/p3_behavioral_cloning/behavioral_cloning_UkiDLucas/output.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "@sio.on('connect')\n",
    "def connect(sid, environ):\n",
    "    print(\"connect \", sid)\n",
    "    send_control(0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def send_control(steering_angle=0.0, throttle=0.2):\n",
    "    sio.emit(\"steer\", data={\n",
    "    'steering_angle': steering_angle.__str__(),\n",
    "    'throttle': throttle.__str__()\n",
    "    }, skip_sid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    #parser = argparse.ArgumentParser(description='Remote Driving')\n",
    "    #parser.add_argument('model', type=str,\n",
    "    #help='Path to model definition h5. Model should be on the same path.')\n",
    "    #args = parser.parse_args()\n",
    "\n",
    "    #model = load_model(args.model)\n",
    "    \n",
    "    \n",
    "    # wrap Flask application with engineio's middleware\n",
    "    app = socketio.Middleware(sio, app)\n",
    "\n",
    "    # deploy as an eventlet WSGI server\n",
    "    eventlet.wsgi.server(eventlet.listen(('', 4567)), app)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "  parser = argparse.ArgumentParser(description='Remote Driving')\n",
    "    parser.add_argument('model', type=str,\n",
    "    help='Path to model definition json. Model weights should be on the same path.')\n",
    "    args = parser.parse_args()\n",
    "    with open(args.model, 'r') as jfile:\n",
    "        model = model_from_json(jfile.read())\n",
    "\n",
    "\n",
    "    model.compile(\"adam\", \"mse\")\n",
    "    weights_file = args.model.replace('json', 'h5')\n",
    "    model.load_weights(weights_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda env carnd-term1",
   "language": "python",
   "name": "carnd-term1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
