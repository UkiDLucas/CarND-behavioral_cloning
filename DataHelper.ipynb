{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWrapper methods around \"import csv\" that\\nare very specific to p3.\\nCreated by Uki D. Lucas on Feb. 4, 2017\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Wrapper methods around \"import csv\" that\n",
    "are very specific to p3.\n",
    "Created by Uki D. Lucas on Feb. 4, 2017\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# snapping actual values to given labels\n",
    "\n",
    "def find_nearest(array,value):\n",
    "    idx = (np.abs(array-value)).argmin()\n",
    "    return array[idx]\n",
    "\n",
    "# TEST\n",
    "#assert (find_nearest(steering_labels, -0.951) == -1.00),\"method find_nearest() has problem\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# TODO implement batch_from, batch_to - I did not need it for 8037 rows\n",
    "# TODO implement has_header_row\n",
    "def read_csv(file_path):\n",
    "    \"\"\"\n",
    "    Usage:\n",
    "    headers, data = read_csv(file_path)\n",
    "    Parameter: \n",
    "    - file_path: can be relative path \"../../../DATA/stuff.csv\"\n",
    "    Returns:\n",
    "    - headers: array of strings e.g. ['steering', 'throttle', 'brake', 'speed']\n",
    "    - data: array of strings, you have to convert values to int, float yourself\n",
    "   test_read_csv()\n",
    "    \"\"\"\n",
    "    import csv\n",
    "    # Opening spreadsheet to read in TEXT mode: 'rt'\n",
    "    with open(file_path, 'rt') as csvfile:\n",
    "        # Most common format of CSV, TODO improve\n",
    "        payload = csv.reader(csvfile, delimiter=',', quotechar='\"') \n",
    "        row_counter = 0\n",
    "        headers = []\n",
    "        data = []\n",
    "        for row in payload:\n",
    "            row_counter = row_counter + 1\n",
    "            \n",
    "            if row_counter == 1:\n",
    "                headers = row\n",
    "                # print (type(row))\n",
    "                # print ( row)\n",
    "                # print ('\\t '.join(row))\n",
    "            elif 1 < row_counter < 3:\n",
    "                # print (type(row))\n",
    "                # print ( row)\n",
    "                # print ('\\t '.join(row))\n",
    "                data.append(row)\n",
    "            else:\n",
    "                data.append(row)\n",
    "        print(\"imported rows\", row_counter)\n",
    "        # I am returning data as numpy array instead of list\n",
    "        # because it is handier to use it.\n",
    "        return headers, np.array(data)\n",
    "    \n",
    "    \n",
    "    \n",
    "def test_read_csv():\n",
    "    \"\"\"\n",
    "    This test is specific to Uki's enviroment.\n",
    "    \"\"\"\n",
    "    data_dir = \"../../../DATA/behavioral_cloning_data/\"\n",
    "    headers, data = read_csv(file_path = data_dir + 'driving_log.csv')\n",
    "    print(\"headers \\n\",headers)\n",
    "    print(\"3rd row of data \\n\",data[2:3])\n",
    "# test_read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "    \n",
    "def split_random(matrix, percent_train=70, percent_test=15):\n",
    "    \"\"\"\n",
    "    Splits matrix data into randomly ordered sets \n",
    "    grouped by provided percentages.\n",
    "    \n",
    "    Usage:\n",
    "    rows = 100\n",
    "    columns = 2\n",
    "    matrix = np.random.rand(rows, columns)\n",
    "    training, testing, validation = \\\n",
    "    split_random(matrix, percent_train=80, percent_test=10)\n",
    "    \n",
    "    percent_validation 10\n",
    "    training (80, 2)\n",
    "    testing (10, 2)\n",
    "    validation (10, 2)\n",
    "    \n",
    "    Returns:\n",
    "    - training_data: percentage_train e.g. 70%\n",
    "    - testing_data: percent_test e.g. 15%\n",
    "    - validation_data: reminder from 100% e.g. 15%\n",
    "    Created by Uki D. Lucas on Feb. 4, 2017\n",
    "    \"\"\"\n",
    "    #print(matrix)  \n",
    "    row_count = matrix.shape[0]\n",
    "    np.random.shuffle(matrix)\n",
    "    \n",
    "    end_training = int(math.ceil(row_count*percent_train/100))    \n",
    "    end_testing = end_training + int(math.ceil((row_count * percent_test/100)))\n",
    "    \n",
    "    percent_validation = 100 - percent_train - percent_test\n",
    "    \n",
    "    training = matrix[:end_training]\n",
    "    testing = []\n",
    "    validation = []\n",
    "    \n",
    "    if percent_validation < 0:\n",
    "        print(\"Make sure that the provided sum of \" + \\\n",
    "        \"training and testing percentages is equal, \" + \\\n",
    "        \"or less than 100%.\")\n",
    "        \n",
    "        testing = matrix[end_training:]\n",
    "    else:\n",
    "        print(\"percent_validation\", percent_validation)\n",
    "        \n",
    "        testing = matrix[end_training:end_testing]\n",
    "        validation = matrix[end_testing:]\n",
    "    \n",
    "    return training, testing, validation\n",
    "\n",
    "# TEST:\n",
    "\n",
    "def test_split_random():\n",
    "    rows = 8037\n",
    "    columns = 2\n",
    "    matrix = np.random.rand(rows, columns)\n",
    "    training, testing, validation = split_random(matrix, percent_train=80, percent_test=20) \n",
    "\n",
    "    print(\"training\",training.shape)\n",
    "    print(\"testing\",testing.shape)\n",
    "    print(\"validation\",validation.shape)\n",
    "    \n",
    "    print(\"sum\",training.shape[0] + testing.shape[0])\n",
    "    \n",
    "    #print(split_random.__doc__)\n",
    "# test_split_random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_image_center_values(matrix):\n",
    "    data = [row[0] for row in matrix]\n",
    "    return np.array(data)\n",
    "\n",
    "def get_image_left_values(matrix):\n",
    "    data = [row[1] for row in matrix]\n",
    "    return np.array(data)\n",
    "\n",
    "def get_image_right_values(matrix):\n",
    "    data = [row[2] for row in matrix]\n",
    "    return np.array(data)\n",
    "\n",
    "def get_steering_values(matrix):\n",
    "    data = [float(row[3]) for row in matrix]\n",
    "    return np.array(data).astype('float32')\n",
    "\n",
    "def get_throttle_values(matrix):\n",
    "    data = [float(row[4]) for row in matrix]\n",
    "    return np.array(data)\n",
    "\n",
    "def get_brake_values(matrix):\n",
    "    data = [float(row[5]) for row in matrix]\n",
    "    return np.array(data)\n",
    "\n",
    "def get_speed_values(matrix):\n",
    "    data = [float(row[6]) for row in matrix]\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def read_image(image_path):\n",
    "    import cv2\n",
    "    # cv2.IMREAD_COLOR \n",
    "    # cv2.COLOR_BGR2GRAY \n",
    "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    #print(\"image shape\", image.shape)\n",
    "    #plt.imshow(image, cmap='gray')\n",
    "    #plt.show()\n",
    "    return np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# for custom metrics\n",
    "import keras.backend as K\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "def false_rates(y_true, y_pred):\n",
    "    false_neg = ...\n",
    "    false_pos = ...\n",
    "    return {\n",
    "        'false_neg': false_neg,\n",
    "        'false_pos': false_pos,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def normalize_grayscale(image_data):\n",
    "    a = -0.5\n",
    "    b = 0.5\n",
    "    grayscale_min = 0\n",
    "    grayscale_max = 255\n",
    "    return a + ( ( (image_data - grayscale_min)*(b - a) )/( grayscale_max - grayscale_min ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def sort_unique_floats(array_x):\n",
    "    # assure that the array is numpy and numerical\n",
    "    #array_x = array_x.astype(np.float)\n",
    "    \n",
    "    # get unique values, a.k.a. set of values\n",
    "    labels_set = set(array_x)\n",
    "    #print(\"labels_set\\n\", labels_set)\n",
    "    \n",
    "    # set is not sorted, so convert it to a numpy array\n",
    "    unique_labels = np.array(list(labels_set))\n",
    "    #print(\"unique_labels\\n\", unique_labels.shape, unique_labels)\n",
    "    \n",
    "    sorted_unique_labels = np.sort(unique_labels)\n",
    "    #print(\"sorted_unique_labels\\n\", sorted_unique_labels.shape, sorted_unique_labels)\n",
    "    return sorted_unique_labels\n",
    "    \n",
    "# TEST   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def encode_one_hot(all_possible_classes, training_labels):\n",
    "    \"\"\"\n",
    "    Creates one hot encoded vector from a list {1D vector (None,)} containing training labels.\n",
    "    - find all unique labels\n",
    "    - count all unique labels\n",
    "    - create a zero filed array, size equal to count of all unique labels\n",
    "    - order the unique values (small to large)\n",
    "    - create empty output matrix\n",
    "    - for each sample's label create zero vector and set one in position of that label\n",
    "    Created by Uki D. Lucas\n",
    "    \"\"\"\n",
    "    all_possible_classes = sort_unique_floats(all_possible_classes)\n",
    "    \n",
    "    # possible float rounding errors\n",
    "    all_possible_classes = np.round_(all_possible_classes, decimals=1)\n",
    "    print(\"all_possible_classes\\n\", all_possible_classes)\n",
    "    \n",
    "    class_count = len(all_possible_classes)\n",
    "    print(\"class_count:\", class_count)\n",
    "    \n",
    "    sample_count = len(training_labels)\n",
    "    print(\"sample_count:\", sample_count)\n",
    "    \n",
    "    one_hot = np.zeros(shape=(sample_count, class_count), dtype=np.int)\n",
    "    print(\"one_hot shape\", one_hot.shape)\n",
    "    #print(\"one_hot 3 shape\", one_hot[3].shape)\n",
    "    #print(\"one_hot 3\", one_hot[3])\n",
    "     \n",
    "    for i in range( sample_count ): \n",
    "        actual_label = float(training_labels[i])\n",
    "        #print(\"looking for actual_label:\", actual_label)\n",
    "        \n",
    "        # find first index of actual_label\n",
    "        item_index = np.where(all_possible_classes == actual_label)[0]\n",
    "        #print(\"found\", item_index)\n",
    "        one_hot[i][item_index] = 1\n",
    "        #print(\"one_hot[i]\", one_hot[i])\n",
    "    print(\"one_hot[0] \\n\", one_hot[0])\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def show_layers(model):\n",
    "    for i in range(len(model.layers)):\n",
    "        layer = model.layers[i]\n",
    "        print(i, \") \",layer.name, \"\\t\\t is trainable: \", layer.trainable)\n",
    "        #layer.trainable = False\n",
    "    return len(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def margin(value):\n",
    "    return value*(5/100)\n",
    "\n",
    "def plot_histogram(name, values, change_step):\n",
    "    \n",
    "    min_value = min(values)\n",
    "    print(\"min_value\", min_value)\n",
    "    max_value = max(values)\n",
    "    print(\"max_value\", max_value)\n",
    "    \n",
    "    spread = max_value-min_value\n",
    "    print(\"spread\", spread)\n",
    "    recommended_bins = math.ceil(spread/change_step)\n",
    "    print(\"recommended number of classes\", recommended_bins)\n",
    "    \n",
    "    bins = np.linspace(math.floor(min(values)), \n",
    "                       math.ceil(max(values)),\n",
    "                       recommended_bins)\n",
    "\n",
    "    plt.xlim([\n",
    "        min_value - margin(min_value), \n",
    "        max_value + margin(max_value)])\n",
    "\n",
    "    plt.hist(values, bins=bins, alpha=0.5)\n",
    "    plt.title('Distribution of ' + name)\n",
    "    plt.xlabel('values')\n",
    "    plt.ylabel('occurance')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    from PIL import Image\n",
    "    image = Image.open(image_path)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda env carnd-term1",
   "language": "python",
   "name": "carnd-term1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
